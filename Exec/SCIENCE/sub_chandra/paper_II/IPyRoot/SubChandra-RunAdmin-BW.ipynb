{
 "metadata": {
  "name": "SubChandra-RunAdmin"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Status"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Status of jobs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "List jobs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This means that modules will be automatically reloaded when changed.  \n",
      "#Makes for swift exporatory development, probably a performance hit if using well-tested code.\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import subchandra as sc\n",
      "STG_DIR = '/u/sciteam/ajacobs/Projects/SubChandra/Runs'\n",
      "WORK_DIR = '/u/sciteam/ajacobs/scratch/sub_chandra'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Scratch                        | Stage\n",
        "1                                1\n",
        "08130-107-185-3lev               08130-107-185-3lev\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runs = listrundirs(WORK_DIR, STG_DIR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Scratch                        | Stage\n",
        "11                               11\n",
        "08120-108-185-3lev               08120-108-185-3lev\n",
        "                                  \n",
        "08130-107-185-3lev               08130-107-185-3lev\n",
        "08130-107-185-4lev-full          08130-107-185-4lev-full\n",
        "                                  \n",
        "10030-108-185-4lev               10030-108-185-4lev\n",
        "                                  \n",
        "10040-108-185-4lev               10040-108-185-4lev\n",
        "                                  \n",
        "11020-108-185-4lev               11020-108-185-4lev\n",
        "                                  \n",
        "11030-108-185-4lev               11030-108-185-4lev\n",
        "                                  \n",
        "12020-107-175-4lev               12020-107-175-4lev\n",
        "12020-108-175-4lev               12020-108-175-4lev\n",
        "                                  \n",
        "12030-107-175-4lev               12030-107-175-4lev\n",
        "12030-108-175-4lev               12030-108-175-4lev\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Running state \n",
      "\n",
      "(of all jobs found in staging directory, if a job is only in scratch it's not examined under that assumption that such jobs are for testing, development, or debugging)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_status(STG_DIR, WORK_DIR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "run label:\n",
        "run status | T_peak | M_peak | time | note \n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "08120-108-185-3lev:\n",
        "\u001b[31minactive\u001b[0;30m*00|\u001b[31m1372221888.0\u001b[0;30m|\u001b[31m1.168060022\u001b[0;30m|244.6467093|Boom with significant r_peak.\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "08130-107-185-3lev:\n",
        "\u001b[31minactive\u001b[0;30m*00|203843459.5|0.05516161104|36.11230968|Titan comparison run\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "08130-107-185-4lev-full:\n",
        "\u001b[31minactive\u001b[0;30m*00|375997452.4|\u001b[31m0.3992728273\u001b[0;30m|146.9973156| \n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10030-108-185-4lev:\n",
        "\u001b[31minactive\u001b[0;30m*00|203473946.6|0.09298569237|447.6542967|Quasi-EQ, but trending up\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10040-108-185-4lev:\n",
        "\u001b[31minactive\u001b[0;30m*00|260473151.0|0.1736818303|621.9488912|About to go boom, but taking its time.\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11020-108-185-4lev:\n",
        "\u001b[31minactive\u001b[0;30m*00|199554792.9|0.09502091181|447.1450121|Almost quasi-EQ, but steadily working to boom.\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11030-108-185-4lev:\n",
        "\u001b[32mrunning\u001b[0;30m*09|351312355.0|\u001b[31m0.2848204055\u001b[0;30m|307.2903715|Needs time...\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12020-107-175-4lev:\n",
        "\u001b[0;34mqueued\u001b[0;30m*09|362090985.7|\u001b[31m0.3002678885\u001b[0;30m|405.2449516|SLOWLY working to boom, but should watch\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12020-108-175-4lev:\n",
        "\u001b[31minactive\u001b[0;30m*00|950024989.7|\u001b[31m0.4289875763\u001b[0;30m|419.4218628|Needs time. (Prior nesting error)\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12030-107-175-4lev:\n",
        "\u001b[31minactive\u001b[0;30m*00|\u001b[31m1529604029.0\u001b[0;30m|\u001b[31m0.2332587049\u001b[0;30m|118.0925100|Heading to boom.\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12030-108-175-4lev:\n",
        "\u001b[31minactive\u001b[0;30m*00|\u001b[31m1510240661.0\u001b[0;30m|\u001b[31m0.6418743435\u001b[0;30m|123.0121175|Heading to boom.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Usage stats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_bw_overview()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "=== Queue Overview ===\n",
        "--------------------------------------------------------------------------------\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r\n",
        "active jobs------------------------\r\n",
        "JOBID              USERNAME      STATE NODES   REMAINING            STARTTIME\r\n",
        "\r\n",
        "\r\n",
        "0 active jobs          0 of 800144 processors in use by local jobs (0.00%)\r\n",
        "                      17492 of 26923 nodes active      (64.97%)\r\n",
        "\r\n",
        "eligible jobs----------------------\r\n",
        "JOBID              USERNAME      STATE NODES     WCLIMIT            QUEUETIME\r\n",
        "\r\n",
        "\r\n",
        "0 eligible jobs   \r\n",
        "\r\n",
        "blocked jobs-----------------------\r\n",
        "JOBID              USERNAME      STATE NODES     WCLIMIT            QUEUETIME\r\n",
        "\r\n",
        "\r\n",
        "0 blocked jobs   \r\n",
        "\r\n",
        "Total jobs:  0\r\n",
        "\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "=== Memory Overview ===\n",
        "--------------------------------------------------------------------------------\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-71d43b7d3fa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint_bw_overview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-6-65b9c4d4c492>\u001b[0m in \u001b[0;36mprint_bw_overview\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#Get HPSS info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#out = !showusage -s hpss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mhpss_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Project quota is currently 50 TB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mhpss_pct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhpss_total\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Scratch work area for operating on runs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Create Jobs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Globals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Globals used by all runs\n",
      "STG_DIR = '/u/sciteam/ajacobs/Projects/SubChandra/Runs'\n",
      "WORK_DIR = '/u/sciteam/ajacobs/scratch/sub_chandra'\n",
      "SUBCH_IM_DIR = '/u/sciteam/ajacobs/Codebase/AstroDev/initial_models/sub_chandra'\n",
      "PARAM_TEMPLATE = '/u/sciteam/ajacobs/Projects/SubChandra/TemplateFiles/_params.M_WD-0.8.M_He-0.025.hotcutoff.hotbase'\n",
      "INPUTS_TEMPLATE = '/u/sciteam/ajacobs/Projects/SubChandra/TemplateFiles/inputs_3d.256.5dr.eq.dx_2levs'\n",
      "JOB_TEMPLATE = '/u/sciteam/ajacobs/Projects/SubChandra/TemplateFiles/bw.run'\n",
      "PROC_SCRIPT = '/u/sciteam/ajacobs/Projects/SubChandra/TemplateFiles/process.bw'\n",
      "MAIN_EXE = '/u/sciteam/ajacobs/Codebase/MAESTRO_Exec/SCIENCE/sub_chandra/main.Linux.Cray.mpi.omp.exe'\n",
      "HELM_DAT = '/u/sciteam/ajacobs/Codebase/MAESTRO_Exec/SCIENCE/sub_chandra/helm_table.dat'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Job Creation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1.2 M$_\\odot$ core"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_12XXX_10Y_ZZZ_Nlev()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1.1 M$_\\odot$ core"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_11XXX_10Y_ZZZ_Nlev()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1.0 M$_\\odot$ core"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_10XXX_10Y_ZZZ_Nlev()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "0.8 M$_\\odot$ core"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_08130_107_185_3lev(bw=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Calling: ./init_1d.Linux.gfortran.debug.exe /u/sciteam/ajacobs/Projects/SubChandra/Runs/08130-107-185-3lev/run/_params.M_WD-0.8.M_He-0.130\n",
        "  in: /mnt/a/u/sciteam/ajacobs/Codebase/AstroDev/initial_models/sub_chandra\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_08130_107_185_3lev_full()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Calling: ./init_1d.Linux.gfortran.debug.exe /u/sciteam/ajacobs/Projects/SubChandra/Runs/08130-107-185-3lev-full/run/_params.M_WD-0.8.M_He-0.130\n",
        "  in: /mnt/a/u/sciteam/ajacobs/Codebase/AstroDev/initial_models/sub_chandra\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_08130_107_185_4lev_full()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Calling: ./init_1d.Linux.gfortran.debug.exe /u/sciteam/ajacobs/Projects/SubChandra/Runs/08130-107-185-4lev-full/run/_params.M_WD-0.8.M_He-0.130\n",
        "  in: /mnt/a/u/sciteam/ajacobs/Codebase/AstroDev/initial_models/sub_chandra\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Archive output files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd /ccs/home/ajacobs/cronjobs\n",
      "!/ccs/home/ajacobs/cronjobs/daily.py\n",
      "%cd -"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/autofs/na3_home1/ajacobs/cronjobs\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/autofs/na3_home1/ajacobs/Projects/SubChandra"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load /ccs/home/ajacobs/cronjobs/logs/daily.outlog\n",
      "%load /ccs/home/ajacobs/cronjobs/logs/daily.errlog"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Imports, Code, and Setup"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Code needed by/available to the entire notebook"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This loads matplotlib for plotting as well as most of the popular scientific computing python packages with\n",
      "#widely used naming convenctions.  e.g. numpy imported as np, matplotlib.plot as plt, etc...\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_run(run_label, param_fullpath, param_dict, inputs_fullpath, inputs_dict, job_dict, bw=False):\n",
      "    \"\"\"Create a sub-Chandrasekhar run.\"\"\"\n",
      "    #TODO:\n",
      "    #  1) Don't use external globals\n",
      "    \n",
      "    #Imports\n",
      "    from subprocess import call\n",
      "    from os import chdir, getcwd, makedirs, chmod\n",
      "    from os.path import basename\n",
      "    from shutil import copy, move\n",
      "    from glob import glob\n",
      "    #Create initial model in AstroDev/\n",
      "        #params filename\n",
      "        #(M_CO, M_He)\n",
      "        #T_base\n",
      "        #npoints\n",
      "        #xmax\n",
      "    #Create parameters file\n",
      "    param_file_parser(PARAM_TEMPLATE, param_dict, param_fullpath)\n",
      "    \n",
      "    #cd into initial model directory (need helmholtz table), removing any old model files\n",
      "    curdir = getcwd()\n",
      "    chdir(SUBCH_IM_DIR)\n",
      "    for old in glob(\"sub_chandra.M_WD*\"):\n",
      "        call([\"rm\", old])\n",
      "    \n",
      "    #Use init1d to create a preliminary initial model file using a large enough radius to\n",
      "    #encompass any likely sub-Chandra system.\n",
      "    print 'Calling: {0} {1}'.format(\"./init_1d.Linux.gfortran.debug.exe\", param_fullpath)\n",
      "    print '  in: {0}'.format(getcwd())\n",
      "    if(bw):\n",
      "        #Blue Waters must have PrgEnv-gnu module loaded, so we have to call via a shell script\n",
      "        call([\"./init_1d.sh\", param_fullpath])\n",
      "    else:\n",
      "        #On Titan at least you only need PrgEnv-gnu for compiling gfort, not running gfort binaries.\n",
      "        call([\"./init_1d.Linux.gfortran.debug.exe\", param_fullpath])\n",
      "        \n",
      "    #Constuct initial model filename\n",
      "    mcostr = param_dict[\"M_tot\"]\n",
      "    mhestr = param_dict[\"M_He\"]\n",
      "    resstr = param_dict[\"nx\"]\n",
      "    imfile = glob(\"sub_chandra.M_WD*hse*\")[0] \n",
      "        \n",
      "    #Based on the preliminary equilibrium model calculate a new xmax.  This will usually be\n",
      "    #smaller than the xmax used in the preliminary model and ensures we don't waste too much of\n",
      "    #the computational domain on regions far from the WD's surface that we don't really care about. \n",
      "    rmax = compute_rmax(imfile, 0.5)\n",
      "    if inputs_dict[\"octant\"] == '.false.':\n",
      "        rmax = rmax*2\n",
      "    param_dict[\"xmax\"] = str(rmax) + 'd0'\n",
      "    param_file_parser(PARAM_TEMPLATE, param_dict, param_fullpath)\n",
      "    \n",
      "    #Sometimes the newly generated model file will have a different name due to\n",
      "    #differences in the last decimal place of the mass (the preliminary model uses such a large radius\n",
      "    #that more compact systems often have more shell mass than we want).  So we remove the preliminary\n",
      "    #model files and rebuild the imfile's name after we've generated the final initial model\n",
      "    for old in glob(\"sub_chandra.M_WD*\"):\n",
      "        call([\"rm\", old])\n",
      "        \n",
      "    #Regenerate initial model file using a smaller max radius based on the preliminary \n",
      "    #equilibrium model we just made\n",
      "    if(bw):\n",
      "        call([\"./init_1d.sh\", param_fullpath])\n",
      "    else:\n",
      "        call([\"./init_1d.Linux.gfortran.debug.exe\", param_fullpath])\n",
      "    inputs_dict[\"prob_hi_x\"] = str(rmax) + 'd0'\n",
      "    inputs_dict[\"prob_hi_y\"] = str(rmax) + 'd0'\n",
      "    inputs_dict[\"prob_hi_z\"] = str(rmax) + 'd0'\n",
      "    imfile = glob(\"sub_chandra.M_WD*hse*\")[0] \n",
      "    inputs_dict[\"model_file\"] = \"\\\"\" + imfile + \"\\\"\"\n",
      "    \n",
      "    #Determine anelastic_cutoff / sponge_center_density from initial model\n",
      "    (ac, scd) = compute_cutoff(imfile, 2.0)\n",
      "    #Convert to str for Fortran inputs file\n",
      "    ac = str(ac) + \"d0\"\n",
      "    scd = str(scd) + \"d0\"\n",
      "    inputs_dict[\"anelastic_cutoff\"] = ac\n",
      "    inputs_dict[\"sponge_center_density\"] = scd\n",
      "    \n",
      "    #cd back\n",
      "    chdir(curdir)\n",
      "    \n",
      "    #Create staging directories\n",
      "        #run designation (#####-#lev-TTT-spt1)\n",
      "    try:\n",
      "        makedirs(STG_DIR + \"/\" + run_label.strip() + \"/run\")\n",
      "    except OSError as ose:\n",
      "        if(ose.errno == 17):\n",
      "            #Directory exists, so we're fine\n",
      "            pass\n",
      "        else:\n",
      "            raise ose\n",
      "    try:\n",
      "        makedirs(STG_DIR + \"/\" + run_label.strip() + \"/plots\")\n",
      "    except OSError as ose:\n",
      "        if(ose.errno == 17):\n",
      "            #Directory exists, so we're fine\n",
      "            pass\n",
      "        else:\n",
      "            raise ose\n",
      "    try:\n",
      "        makedirs(STG_DIR + \"/\" + run_label.strip() + \"/output\")\n",
      "    except OSError as ose:\n",
      "        if(ose.errno == 17):\n",
      "            #Directory exists, so we're fine\n",
      "            pass\n",
      "        else:\n",
      "            raise ose\n",
      "    \n",
      "    #Move hse and extras to staging directory, overwriting any version that may exist\n",
      "    copy(SUBCH_IM_DIR + \"/\" + imfile.strip(),\n",
      "         STG_DIR + \"/\" + run_label.strip() + \"/run/\")\n",
      "    copy(SUBCH_IM_DIR + \"/\" + imfile.replace(\"hse\",\"extras\").strip(),\n",
      "         STG_DIR + \"/\" + run_label.strip() + \"/run/\")\n",
      "    \n",
      "    #Generate inputs file\n",
      "        #job name\n",
      "        #model_file\n",
      "        #coarse resolution\n",
      "        #max_levs\n",
      "        #base_cutoff_density\n",
      "        #octant\n",
      "        #prob_hi_x[y,z]\n",
      "        #plot_base_name\n",
      "        #plot_deltat\n",
      "        #check_base_name\n",
      "        #chk_int\n",
      "    param_file_parser(INPUTS_TEMPLATE, inputs_dict, inputs_fullpath)\n",
      "    \n",
      "    #Prepare run scripts\n",
      "    copy(PROC_SCRIPT,\n",
      "         STG_DIR + \"/\" + run_label.strip() + \"/run/\")\n",
      "    job_script_parser(JOB_TEMPLATE, job_dict, \n",
      "                      STG_DIR + '/' + run_label.strip() + '/run/' + basename(JOB_TEMPLATE))\n",
      "    chmod(STG_DIR + '/' + run_label.strip() + '/run/' + basename(JOB_TEMPLATE), 0755)\n",
      "    \n",
      "    #Copy over executable + helm table\n",
      "    copy(MAIN_EXE,\n",
      "         STG_DIR + \"/\" + run_label.strip() + \"/run/\")\n",
      "    copy(HELM_DAT,\n",
      "         STG_DIR + \"/\" + run_label.strip() + \"/run/\")\n",
      "        \n",
      "    #Copy files to scratch for running, make dir if needed\n",
      "    try:\n",
      "        makedirs(WORK_DIR + \"/\" + run_label.strip())\n",
      "    except OSError as ose:\n",
      "        if(ose.errno == 17):\n",
      "            #Directory exists, so we're fine\n",
      "            pass\n",
      "        else:\n",
      "            raise ose\n",
      "    for f in glob(STG_DIR + \"/\" + run_label.strip() + \"/run/*\"):\n",
      "        copy(f, WORK_DIR + \"/\" + run_label.strip() + \"/\")\n",
      "    \n",
      "    return\n",
      "\n",
      "def compute_cutoff(imfile, sp_st_fac):\n",
      "    \"\"\"Compute the anelastic_cutoff/sponge_center_density by finding the density coinciding\n",
      "        with the point at which the temperature levels off at the surface of the star.\n",
      "\n",
      "        imfile    --> initial model file\n",
      "        sp_st_fac --> sponge start factor (often 2.0)\"\"\"\n",
      "    #Load data into arrays\n",
      "    rho, temp = np.loadtxt(imfile, usecols=(1,2), unpack=True)\n",
      "        \n",
      "    #Search from end of temp array until the temp changes, this is the top of\n",
      "    #the convective zone.  Base cutoffs on the density at this point.\n",
      "    te_prev = temp[len(temp)-1]\n",
      "    rho_top = -1.0\n",
      "    for re, te in zip(rho[::-1], temp[::-1]):\n",
      "        if(te_prev != te):\n",
      "            rho_top = re\n",
      "            break\n",
      "    an_cut = rho_top/sp_st_fac\n",
      "    sp_c_den = an_cut\n",
      "    return (round(an_cut, -3), round(sp_c_den, -3))\n",
      "\n",
      "def compute_rmax(imfile, r_fac):\n",
      "    \"\"\"Compute the maximum radius for an initial model.  The radius returned will be \n",
      "        R(top) + R(top)*r_fac where R(top) the the radius of the top of the convective\n",
      "        zone as determined by the location at which the temperature levels off at the \n",
      "        surface of the star.\n",
      "\n",
      "        imfile --> initial model file\n",
      "        r_fac  --> factor by which to extend rmax beyond the top of the convective zone\"\"\"\n",
      "    #Load data into arrays\n",
      "    r, temp = np.loadtxt(imfile, usecols=(0,2), unpack=True)\n",
      "        \n",
      "    #Search from end of temp array until the temp changes, this is the top of\n",
      "    #the convective zone.  Base rmax on the radius at this point.\n",
      "    te_prev = temp[len(temp)-1]\n",
      "    r_top = -1.0\n",
      "    for re, te in zip(r[::-1], temp[::-1]):\n",
      "        if(te_prev != te):\n",
      "            r_top = re\n",
      "            break\n",
      "    rmax = r_top + r_top*r_fac\n",
      "    return round(rmax, -7)\n",
      "\n",
      "def param_file_parser(template_file, param_dict, outfile):\n",
      "    \"\"\"Read in a file with simple param = val entries setting any params found in\n",
      "        param_dict, save changed file as outfile\"\"\"\n",
      "    from os.path import dirname, exists\n",
      "    from os import makedirs\n",
      "    \n",
      "    #Open template parameter file, create outfile\n",
      "    temp = open(template_file, 'r')\n",
      "    outdir = dirname(outfile)\n",
      "    if(not exists(outdir)):\n",
      "        makedirs(outdir)\n",
      "    out = open(outfile, 'w')\n",
      "    \n",
      "    #Parse file line-by-line, changing parameters matching keys in param_dict\n",
      "    for line in temp:\n",
      "        if(line.find('=') != -1):\n",
      "            tokens = line.partition('=')\n",
      "            val = tokens[2]\n",
      "            if(tokens[0].strip() in param_dict):\n",
      "                val = param_dict[tokens[0].strip()] + '\\n'\n",
      "            newline = tokens[0].rstrip() + ' = ' + val.lstrip()\n",
      "            out.write(newline)\n",
      "        else:\n",
      "            out.write(line)\n",
      "        \n",
      "    #Close files\n",
      "    temp.close()\n",
      "    out.close()    \n",
      "    return\n",
      "\n",
      "def job_script_parser(template_file, job_dict, outfile):\n",
      "    \"\"\"Read in a job script, set any entries found in\n",
      "        job_dict, save changed file as outfile\"\"\"\n",
      "    from os.path import dirname, exists\n",
      "    from os import makedirs\n",
      "    \n",
      "    #Open template job file, create outfile\n",
      "    temp = open(template_file, 'r')\n",
      "    outdir = dirname(outfile)\n",
      "    if(not exists(outdir)):\n",
      "        makedirs(outdir)\n",
      "    out = open(outfile, 'w')\n",
      "    \n",
      "    #Parse file line-by-line, changing parameters matching keys in job_dict\n",
      "    #TODO: Make this more efficient?\n",
      "    for line in temp:\n",
      "        newline = line\n",
      "        for key in job_dict:\n",
      "            if(line.lstrip().startswith(key)):\n",
      "                newline = key + job_dict[key] + '\\n'\n",
      "        out.write(newline)    \n",
      "        \n",
      "    #Close files\n",
      "    temp.close()\n",
      "    out.close()\n",
      "    return\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#These are ANSI escape sequences for adding color to terminal output. \\033 is octal for the ASCII escape character.\n",
      "#For more info see http://ascii-table.com/ansi-escape-sequences.php\n",
      "start_red = \"\\033[31m\"\n",
      "start_green = \"\\033[32m\"\n",
      "start_blue = \"\\033[0;34m\"\n",
      "end = \"\\033[0;30m\"\n",
      "\n",
      "#Temperature and Mach number tolerances.  Values larger than this will be flagged in red.\n",
      "TEMP_TOL = 1.e9\n",
      "MACH_TOL = 0.2\n",
      "\n",
      "def print_status(stg_dir, wrk_dir):\n",
      "    \"\"\"Go through all runs in the staging directory, printing out:\n",
      "           run status (queued, running, or inactive)\n",
      "           T_peak\n",
      "           M_peak\n",
      "           Simulation time\"\"\"\n",
      "    print('run label:')\n",
      "    print('run status | T_peak | M_peak | time | note \\n')\n",
      "        \n",
      "    #Loop over all runs in staging directory assuming <run label>/[output, run, plots]\n",
      "    #structure\n",
      "    runs = !\\ls $stg_dir\n",
      "    for rdir in runs:\n",
      "        #Skip inactive\n",
      "        if(rdir in ['inactive', 'README']):\n",
      "            continue\n",
      "        \n",
      "        #Get properties\n",
      "        rstat = get_rstat(rdir, stg_dir, wrk_dir)\n",
      "        tpeak = get_tpeak(rdir, stg_dir, wrk_dir)\n",
      "        mpeak = get_mpeak(rdir, stg_dir, wrk_dir)\n",
      "        time = get_time(rdir, stg_dir, wrk_dir)\n",
      "        note = get_note(rdir, stg_dir, wrk_dir)\n",
      "        \n",
      "        #Print\n",
      "        print(rdir + \":\\n\" + rstat + \"|\" + tpeak + \"|\" + mpeak + \"|\" + time + \"|\" + note + '\\n')\n",
      "        \n",
      "    return\n",
      "\n",
      "def get_rstat(rdir, stg_dir, wrk_dir):\n",
      "    \"\"\"Use commandline tools to determine run status of rdir\"\"\"\n",
      "    #ASSUMPTIONS:\n",
      "    #  +rdir is the same as the name of the job\n",
      "    \n",
      "    #Get a list of all of my job ids (-n +6 starts at line 6, the first non-header line)\n",
      "    qcount = 0\n",
      "    jobs = !qstat -u ajacobs | tail -n +6\n",
      "    job_status = start_red + 'inactive' + end\n",
      "    for line in jobs:  #Loop over each job\n",
      "        tokens = line.split()\n",
      "        jobid = tokens[0]\n",
      "        jobname = tokens[3]\n",
      "        if rdir.startswith(jobname.strip()):\n",
      "            qcount += 1\n",
      "            jobstate = tokens[9]\n",
      "            if(job_status.count('inactive') > 0):\n",
      "                if jobstate == 'R':\n",
      "                    job_status = start_green + 'running' + end\n",
      "                if jobstate == 'Q':\n",
      "                    job_status = start_blue + 'queued' + end\n",
      "                if jobstate == 'H':\n",
      "                    job_status = start_blue + 'holding' + end    \n",
      "    return job_status + '*{0:02d}'.format(qcount)\n",
      "\n",
      "\n",
      "#def get_rstat(rdir, stg_dir, wrk_dir):\n",
      "#    \"\"\"Use commandline tools to determine run status of rdir\"\"\"\n",
      " #   #ASSUMPTIONS:\n",
      "  #  #  +rdir is the same as the name of the job\n",
      "    \n",
      "    #Get a list of all of my job ids (-n +6 starts at line 6, the first non-header line)\n",
      "#    jobs = !qstat -u ajacobs | tail -n +6\n",
      "#    job_status = start_red + 'inactive' + end\n",
      "#    for line in jobs:  #Loop over each job\n",
      "#        tokens = line.split()\n",
      "#        jobid = tokens[0]\n",
      "#        jobinfo = !qstat -f1 $jobid\n",
      "#        found = False\n",
      "#        for info_line in jobinfo: #Loop over info about this job\n",
      "#            tokens = info_line.partition('=')\n",
      "            #If '=' was found, check for info\n",
      "#            if(tokens[1]):\n",
      "#                if(tokens[0].strip() == 'Job_Name' and tokens[2].strip() == rdir):\n",
      "#                    found = True\n",
      "#                if(found and tokens[0].strip() == 'job_state'):\n",
      "#                    if(tokens[2].strip() == 'R'):\n",
      "#                        return start_green + 'running' + end\n",
      "#                    elif(tokens[2].strip() == 'Q'):\n",
      "#                        return start_blue + 'queued' + end\n",
      "#    return job_status\n",
      "\n",
      "def get_tpeak(rdir, stg_dir, wrk_dir):\n",
      "    \"\"\"Return the largest temperature found in diagnostic .out files with a preference for\n",
      "       files found in the work directory\"\"\"\n",
      "    import os\n",
      "    \n",
      "    #Check work directory\n",
      "    if(os.path.isfile(wrk_dir + '/' + rdir + '/subchandra_temp_diag.out')):\n",
      "        diag_file = wrk_dir + '/' + rdir + '/subchandra_temp_diag.out'\n",
      "        temps = np.loadtxt(diag_file, usecols=(1,), unpack=True)\n",
      "        maxt = max(temps)\n",
      "        if(maxt > TEMP_TOL): \n",
      "            return start_red + str(maxt) + end\n",
      "        else:\n",
      "            return str(maxt)\n",
      "                \n",
      "    #If no luck, check staging directory\n",
      "    if(os.path.isfile(stg_dir + '/' + rdir + '/output/subchandra_temp_diag.out')):\n",
      "        diag_file = stg_dir + '/' + rdir + '/output/subchandra_temp_diag.out'\n",
      "        temps = np.loadtxt(diag_file, usecols=(1,), unpack=True)\n",
      "        maxt = max(temps)\n",
      "        if(maxt > TEMP_TOL): \n",
      "            return start_red + str(maxt) + end\n",
      "        else:\n",
      "            return str(maxt)\n",
      "    return 'no files'\n",
      "\n",
      "def get_mpeak(rdir, stg_dir, wrk_dir):\n",
      "    \"\"\"Return the largest Mach number found in diagnostic .out files with a preference for\n",
      "       files found in the work directory\"\"\"\n",
      "    import os\n",
      "    \n",
      "    #Check work directory\n",
      "    if(os.path.isfile(wrk_dir + '/' + rdir + '/subchandra_vel_diag.out')):\n",
      "        diag_file = wrk_dir + '/' + rdir + '/subchandra_vel_diag.out'\n",
      "        machnums = np.loadtxt(diag_file, usecols=(3,), unpack=True)\n",
      "        maxm = max(machnums)\n",
      "        if(maxm > MACH_TOL): \n",
      "            return start_red + str(maxm) + end\n",
      "        else:\n",
      "            return str(maxm)\n",
      "                \n",
      "    #If no luck, check staging directory\n",
      "    if(os.path.isfile(stg_dir + '/' + rdir + '/output/subchandra_vel_diag.out')):\n",
      "        diag_file = stg_dir + '/' + rdir + '/output/subchandra_vel_diag.out'\n",
      "        machnums = np.loadtxt(diag_file, usecols=(3,), unpack=True)\n",
      "        maxm = max(machnums)\n",
      "        if(maxm > MACH_TOL): \n",
      "            return start_red + str(maxm) + end\n",
      "        else:\n",
      "            return str(maxm)\n",
      "    return 'no files'\n",
      "\n",
      "def get_time(rdir, stg_dir, wrk_dir):\n",
      "    \"\"\"Return the latest time found in diagnostic .out files with a preference for\n",
      "       files found in the work directory\"\"\"\n",
      "    import os\n",
      "    \n",
      "    #Check work directory\n",
      "    if(os.path.isfile(wrk_dir + '/' + rdir + '/subchandra_temp_diag.out')):\n",
      "        diag_file = wrk_dir + '/' + rdir + '/subchandra_temp_diag.out'\n",
      "        last_line = !tail -n 1 $diag_file\n",
      "        tokens = last_line[0].split()\n",
      "        return tokens[0]\n",
      "        \n",
      "    #If no luck, check staging directory\n",
      "    if(os.path.isfile(stg_dir + '/' + rdir + '/output/subchandra_temp_diag.out')):\n",
      "        diag_file = stg_dir + '/' + rdir + '/output/subchandra_temp_diag.out'\n",
      "        last_line = !tail -n 1 $diag_file\n",
      "        tokens = last_line[0].split()\n",
      "        return tokens[0]\n",
      "    return 'no files'\n",
      "\n",
      "def get_note(rdir, stg_dir, wrk_dir):\n",
      "    \"\"\"Return the any short note found in the staging directory's out directory\n",
      "       as note.txt.\"\"\"\n",
      "    import os\n",
      "    \n",
      "    #Check for a note, return it if it exists\n",
      "    if(os.path.isfile(stg_dir + '/' + rdir + '/output/note.txt')):\n",
      "        note_file = stg_dir + '/' + rdir + '/output/note.txt'\n",
      "        with open(note_file, 'r') as nf:\n",
      "            for i, l in enumerate(nf):\n",
      "                assert (i == 0), 'Error! note.txt should have only one line!'\n",
      "                txt = l\n",
      "        return txt.strip('\\n')\n",
      "    \n",
      "    #Otherwise, return a blank\n",
      "    return ' '"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def listrundirs(scdir, stagedir):\n",
      "    \"\"\"Display columns comparing the scratch and stage run directories in scdir, stagedir.\n",
      "    Return a list of directories found in stage.\"\"\"\n",
      "\n",
      "    scruns = !ls $scdir | grep ^[0-9]\n",
      "    stgruns = !ls $stagedir | grep ^[0-9]\n",
      "\n",
      "    scmx = len(scruns)\n",
      "    stgmx = len(stgruns)\n",
      "    prelen = 5\n",
      "\n",
      "    print 'Scratch'.ljust(30), '|', 'Stage'\n",
      "    print scmx.__str__().ljust(32), stgmx\n",
      "    \n",
      "    scruns.reverse()\n",
      "    stgruns.reverse()\n",
      "    scold = None\n",
      "    stgold = None\n",
      "    ret = []\n",
      "    while (len(scruns) > 0) or (len(stgruns) > 0):\n",
      "        cursc = None\n",
      "        curstg = None\n",
      "        \n",
      "        #If we've popped all the elements from the stack, then just print\n",
      "        #blank space for the run\n",
      "        if len(scruns) == 0:\n",
      "            cursc = ' '\n",
      "        else:\n",
      "            #If this is the first run, pop the run from the stack\n",
      "            if scold == None:\n",
      "                cursc = scruns.pop()\n",
      "                scold = cursc\n",
      "            #Otherwise check to see if we need to insert a newline due to a new prefix\n",
      "            elif scold[:prelen] != scruns[len(scruns)-1][:prelen]:\n",
      "                cursc = ' '\n",
      "                scold = scruns[len(scruns)-1][:prelen] #Give scold a matching prefix\n",
      "            else:\n",
      "                cursc = scruns.pop()\n",
      "                scold = cursc\n",
      "                \n",
      "        #If we've popped all the elements from the stack, then just print\n",
      "        #blank space for the run\n",
      "        if len(stgruns) == 0:\n",
      "            curstg = ' '\n",
      "        else:\n",
      "            #If this is the first run, pop the run from the stack\n",
      "            if stgold == None:\n",
      "                curstg = stgruns.pop()\n",
      "                stgold = curstg\n",
      "            #Otherwise check to see if we need to insert a newline due to a new prefix\n",
      "            elif stgold[:prelen] != stgruns[len(stgruns)-1][:prelen]:\n",
      "                curstg = ' '\n",
      "                stgold = stgruns[len(stgruns)-1][:prelen] #Give stgold a matching prefix\n",
      "            else:\n",
      "                curstg = stgruns.pop()\n",
      "                stgold = curstg\n",
      "                \n",
      "        #Print the results\n",
      "        print cursc.ljust(32), curstg\n",
      "        if curstg.strip():\n",
      "            ret.append(curstg)\n",
      "    return ret"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_bw_overview():\n",
      "    print '=== Queue Overview ==='\n",
      "    print '--------------------------------------------------------------------------------'\n",
      "    !showq -n -w user=ajacobs\n",
      "    print ' '\n",
      "    \n",
      "    print '=== Memory Overview ==='\n",
      "    print '--------------------------------------------------------------------------------'\n",
      "    #Get user home info\n",
      "    out = !quota -Qug\n",
      "    tokens = out[7].split()\n",
      "    pct = float(tokens[1][:-1])/float(tokens[2][:-1]) #The [:-1] strips the 'G' from the string\n",
      "    pct = '{0:.2%}'.format(pct)\n",
      "    hm_used = tokens[1]\n",
      "    hm_total = tokens[2]\n",
      "    \n",
      "    #Get HPSS info\n",
      "    #out = !showusage -s hpss\n",
      "    tokens = out[25].split()\n",
      "    hpss_total = tokens[4] #Project quota is currently 50 TB\n",
      "    hpss_pct = float(tokens[2][:-1])/float(hpss_total[:-1])\n",
      "    hpss_pct = '{0:.2%}'.format(hpss_pct)\n",
      "    hpss_used = tokens[2]\n",
      "    #Print\n",
      "    print('User Home: ' + hm_used + '/' + hm_total + ' (' + pct + ' used)') \n",
      "    print('Proj HPSS: ' + hpss_used + '/' + hpss_total + ' (' + hpss_pct + ' used)') \n",
      "    print ' '\n",
      "    print '=== Node-hour Overview ==='\n",
      "    print '--------------------------------------------------------------------------------'\n",
      "    ustr = !usage\n",
      "    tokens = ustr[2].split()\n",
      "    me = float(tokens[3]) / float(tokens[5]) * 100\n",
      "    proj = float(tokens[6]) / float(tokens[5]) * 100\n",
      "    print 'ajacobs:      ', tokens[3], '/', tokens[5]\n",
      "    print 'My usage %:   ', me\n",
      "    print 'Proj usage %: ', proj\n",
      "    print 'My fraction of proj usage %:', me/proj*100."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_imodel(job_label, stg_dir, work_dir):\n",
      "    \"\"\"Plot the initial model with cutoffs for the run in stg_dir/job_label.\"\"\"\n",
      "    #Imports\n",
      "    from glob import glob\n",
      "    from os import path\n",
      "    \n",
      "    #Constants\n",
      "    TEMP_PAD = 25.e6\n",
      "    \n",
      "    #Run-specific directories\n",
      "    run_dir = stg_dir + '/' + job_label + '/run/'\n",
      "    run_wrk_dir = work_dir + '/' + job_label + '/'\n",
      "    \n",
      "    #Generate initial model file string\n",
      "    #  ASSUMPTION: only one initial model file in staging directory, contains 'hse' in name\n",
      "    imfile = glob(run_dir + '*hse*')[0]\n",
      "    \n",
      "    #Determine axis limits\n",
      "    #  Temperature\n",
      "    #  For now fix it at 1e7 K to 5e8 K\n",
      "    #  ASSUMPTION: only one parameters file in staging directory, is prefixed with '_params'\n",
      "    param_file = glob(run_dir + '_params*')[0]\n",
      "    tcore = float(get_param('temp_core', param_file).replace('d', 'e')) #Fortran literal --> Python literal\n",
      "    tbase = float(get_param('temp_base', param_file).replace('d', 'e'))\n",
      "    #Tlims=(tcore, tbase + TEMP_PAD)\n",
      "    Tlims=(1.e7, 5.e8)\n",
      "    \n",
      "    #  Density\n",
      "    #  For now, fix it at 1 to 1e9\n",
      "    dlims = (1.0, 1.e9)\n",
      "    \n",
      "    #  Radius\n",
      "    #  Go from 0 to xmax in parameters file\n",
      "    rmax = float(get_param('xmax', param_file).replace('d', 'e'))\n",
      "    rlims = (0., rmax)\n",
      "    \n",
      "    #  Soundspeed\n",
      "    clims = (1.e7, 1.e10)\n",
      "    \n",
      "    #Determine zoom bounds\n",
      "    rtop, dtop, Ttop = get_top(imfile)\n",
      "    rzoom = (rtop - rtop*0.05, rtop + rtop*0.15)\n",
      "    dzoom = (dtop - dtop*0.25, dtop + dtop*1.5)\n",
      "    Tzoom = (Ttop - Ttop*0.25, Ttop + Ttop*1.5)\n",
      "    zbounds = (rzoom, dzoom, Tzoom)\n",
      "    \n",
      "    #Read in cutoffs\n",
      "    inputs_file = glob(run_dir + 'inputs*')[0]\n",
      "    an_cut = float(get_param('anelastic_cutoff', inputs_file).replace('d', 'e'))\n",
      "    sp_cen_den = float(get_param('sponge_center_density', inputs_file).replace('d', 'e'))\n",
      "    sp_st_fac = float(get_param('sponge_start_factor', inputs_file).replace('d', 'e'))\n",
      "    base_cut = float(get_param('base_cutoff_density', inputs_file).replace('d', 'e'))\n",
      "    \n",
      "    #Check that stage and work directory files match\n",
      "    wrk_inputs_file = glob(run_wrk_dir + 'inputs*')[0]\n",
      "    wrk_imfile = glob(run_wrk_dir + '*hse*')[0]\n",
      "    wrk_job_file = run_wrk_dir + 'titan.run'\n",
      "    job_file = run_dir + 'titan.run'\n",
      "    diffout = !diff $inputs_file $wrk_inputs_file\n",
      "    if(diffout): #If diff's output isn't empty, we have differences\n",
      "        print(\"Oh no!  Stage and work directory inputs don't match!\")\n",
      "        !diff $inputs_file $wrk_inputs_file\n",
      "        print(' ')\n",
      "    diffout = !diff $imfile $wrk_imfile\n",
      "    if(diffout): #If diff's output isn't empty, we have differences\n",
      "        print(\"Oh no!  Stage and work directory initial model files don't match!\")\n",
      "        !diff $imfile $wrk_imfile\n",
      "        print(' ')\n",
      "    diffout = !diff $job_file $wrk_job_file\n",
      "    if(diffout): #If diff's output isn't empty, we have differences\n",
      "        print(\"Oh no!  Stage and work directory job scripts don't match!\")\n",
      "        !diff $job_file $wrk_job_file\n",
      "        print(' ')\n",
      "    \n",
      "    #Plot the initial model\n",
      "    #  TODO: I'm going to make use of plot_initial_model(), which is in desperate need of \n",
      "    #  cleanup, but for now it'll have to do.\n",
      "    plot_initial_model(imfile, Tlims, dlims, rlims, clims, zbounds, an_cut, sp_cen_den, sp_st_fac, base_cut)\n",
      "\n",
      "def get_param(param, param_file):\n",
      "    \"\"\"Return the parameter value (as a string) found in a simple parameter \n",
      "       file with <param> = <val> assignments.  None is returned if not found.\"\"\"\n",
      "    pfile = open(param_file)\n",
      "    ret = None\n",
      "    for line in pfile:\n",
      "        if(line.find('=') > -1):\n",
      "            tokens = line.partition('=')\n",
      "            cur_param = tokens[0].strip()\n",
      "            cur_val = tokens[2]\n",
      "            if(cur_param == param):\n",
      "                ret = cur_val\n",
      "    pfile.close()\n",
      "    return ret\n",
      "\n",
      "def get_top(imfile):\n",
      "    \"\"\"Return tuple of (radius, density, temperature) values at the top of the convective zone\n",
      "       (where temperature levels out).\"\"\"\n",
      "    #Load data into arrays\n",
      "    r, rho, temp = np.loadtxt(imfile, usecols=(0,1,2), unpack=True)\n",
      "        \n",
      "    #Search from end of temp array until the temp changes, this is the top of\n",
      "    #the convective zone.  return values at this point.\n",
      "    te_prev = temp[len(temp)-1]\n",
      "    r_top = -1.0\n",
      "    rho_top = -1.0\n",
      "    T_top = -1.0\n",
      "    for re, rhoe, te in zip(r[::-1], rho[::-1], temp[::-1]):\n",
      "        if(te_prev != te):\n",
      "            r_top = re\n",
      "            rho_top = rhoe\n",
      "            T_top = te\n",
      "            break\n",
      "    return (r_top, rho_top, T_top)    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_initial_model(imfile, Tlims, dlims, rlims, clims, zbounds, an_cut, sp_cen_den, sp_st_fac, base_cut):\n",
      "    \"\"\"Plot the initial model temperature and density profiles with cutoffs overlayed.\n",
      "\n",
      "    imfile:     The file with the initial model, generated by init1d in AstroDev/initial_models/sub_chandra\n",
      "    Tlims:      Tuple of the temperature limits for the plot range: (lower bound, upper bound)\n",
      "    dlims:      Tuple of the density limits for the plot range\n",
      "    rlims:      Tuple of the radius limits for the plot range\n",
      "    clims:      Tuple of the soundspeed limits for the plot range\n",
      "    zbounds:    Tuple of the boundaries for the zoomed inset\n",
      "    an_cut:     The anelastic cutoff density\n",
      "    sp_cen_den: The sponge_center_density\n",
      "    sp_st_fac:  The sponge_start_factor\n",
      "    base_cut:   The base_cutoff_density\"\"\"\n",
      "    import dataRead\n",
      "    from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
      "    from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
      "\n",
      "\n",
      "    initialModel = imfile\n",
      "    initialData = dataRead.getData(initialModel)\n",
      "    extraData = dataRead.getData(initialModel.replace('hse','extras'))\n",
      "    #initialData[n,i]:\n",
      "    # n --> row\n",
      "    # i --> variable\n",
      "    #   i = 0 --> radius\n",
      "    #       1 --> density\n",
      "    #       2 --> temp\n",
      "\n",
      "    #-----------------------------------------------------------------------\n",
      "    # initial model\n",
      "\n",
      "    # find the r coordinate of the anelastic cutoff\n",
      "    n = 0\n",
      "    while (n < len(initialData[:,1])):\n",
      "        if (initialData[n,1] <= an_cut):\n",
      "            r_an = initialData[n,0]\n",
      "            break\n",
      "        n += 1\n",
      "\n",
      "    # find the r coordinate of the middle of the sponge\n",
      "    n = 0\n",
      "    while (n < len(initialData[:,1])):\n",
      "        if (initialData[n,1] <= sp_cen_den):\n",
      "            r_md = initialData[n,0]\n",
      "            break\n",
      "        n += 1\n",
      "\n",
      "    # find the r coordinate of the start of the sponge\n",
      "    sponge_start = sp_st_fac*sp_cen_den\n",
      "    n = 0\n",
      "    while (n < len(initialData[:,1])):\n",
      "        if (initialData[n,1] <= sponge_start):\n",
      "            r_sp = initialData[n,0]\n",
      "            break\n",
      "        n += 1\n",
      "        \n",
      "    # compute the r coordinate of the top of the sponge\n",
      "    r_tp = 2*r_md - r_sp\n",
      "\n",
      "    # find the r coordinate of the cutoff density\n",
      "    n = 0\n",
      "    while (n < len(initialData[:,1])):\n",
      "        if (initialData[n,1] <= base_cut):\n",
      "            r_bc = initialData[n,0]\n",
      "            break\n",
      "        n += 1\n",
      "     \n",
      "    # find the r coordinate of the inner velocity perturbation boundary\n",
      "    n = 0\n",
      "    while (n < len(initialData[:,1])):\n",
      "        if (initialData[n,5] <= 0.9):\n",
      "            r_inp = initialData[n,0]\n",
      "            break\n",
      "        n += 1\n",
      "\n",
      "\n",
      "    # make the plots\n",
      "    \n",
      "    fig, ax_list = plt.subplots(nrows=3, ncols=1)\n",
      "\n",
      "    #-------------------------------------------------------------------------\n",
      "    # density and temperature plots\n",
      "    #-------------------------------------------------------------------------\n",
      "      \n",
      "    sp = ax_list[0]    \n",
      "    sp.set_yscale('log')\n",
      "\n",
      "    # density\n",
      "\n",
      "    # model 1\n",
      "    sp.plot(initialData[:,0], initialData[:,1], color=\"blue\")\n",
      "\n",
      "    # draw in the sponge start, anelastic cutoff, and base cutoff density\n",
      "    sp.plot([r_an, r_an ], [dlims[0], 10.0*dlims[1]], color=\"0.65\")\n",
      "    print('an cutoff:', r_an)\n",
      "    sp.plot([r_sp, r_sp ], [dlims[0], 10.0*dlims[1]], color=\"0.65\")\n",
      "    print('sponge start:', r_sp)\n",
      "    sp.plot([r_bc, r_bc ], [dlims[0], 10.0*dlims[1]], color=\"0.65\")\n",
      "    print('base cutoff den:', r_bc)\n",
      "    #pylab.plot([r_inp, r_inp ], [dlims[0], 10.0*dlims[1]], color=\"0.00\")\n",
      "    #print('inner pert: ', r_inp)\n",
      "    #r_outp = (r_inp+r_sp)/2.0\n",
      "    #pylab.plot([r_outp, r_outp ], [dlims[0], 10.0*dlims[1]], color=\"0.00\")\n",
      "    #print('outer pert: ', r_outp)\n",
      "\n",
      "    #pylab.xlabel(\"r (cm)\")\n",
      "    sp.set_ylabel(r\"density (g cm$^{-3}$)\", color=\"blue\")\n",
      "\n",
      "    sp.set_xlim(rlims[0], rlims[1])\n",
      "    sp.set_ylim(dlims[0], dlims[1])\n",
      "\n",
      "    # the offset text is the 1.e8 that appears under the axis labels when\n",
      "    # doing scientific notation\n",
      "    sp.tick_params(labeltop='off')\n",
      "    sp.tick_params(labelbottom='off')\n",
      "    sp.xaxis.offsetText.set_visible(False)\n",
      "\n",
      "    # temperature\n",
      "    sp2 = sp.twinx()\n",
      "    sp2.set_yscale('log')\n",
      "\n",
      "    # model 1\n",
      "    sp2.plot(initialData[:,0], initialData[:,2], color=\"red\")\n",
      "\n",
      "    sp2.yaxis.tick_right()\n",
      "    sp2.axis(labelcolor=\"red\")\n",
      "    sp2.set_ylabel(r\"temperature (K)\", color=\"red\")\n",
      "\n",
      "    sp2.set_xlim(rlims[0], rlims[1])\n",
      "    sp2.set_ylim(Tlims[0], Tlims[1])\n",
      "    \n",
      "    # zoomed inset\n",
      "    #axins = zoomed_inset_axes(sp, 2, loc=3) # zoom = 2, location = 3 (lower left)\n",
      "    axins = fig.add_axes([0.175, 0.75, 0.30, 0.10])\n",
      "    axins.set_yscale('log')\n",
      "    axins.plot(initialData[:,0], initialData[:,1], color=\"blue\")\n",
      "    axins_twin = axins.twinx() \n",
      "    axins_twin.set_yscale('log')\n",
      "    axins_twin.plot(initialData[:,0], initialData[:,2], color=\"red\")\n",
      "    axins.plot([r_an, r_an ], [dlims[0], 10.0*dlims[1]], color=\"0.65\")\n",
      "    axins.plot([r_sp, r_sp ], [dlims[0], 10.0*dlims[1]], color=\"0.65\")\n",
      "    axins.plot([r_bc, r_bc ], [dlims[0], 10.0*dlims[1]], color=\"0.65\")\n",
      "        \n",
      "    #axins.set_xlim(0.7e9, 0.78e9)\n",
      "    axins.set_xlim(zbounds[0][0], zbounds[0][1])\n",
      "    #axins.set_ylim(2.e3, 2.e5)\n",
      "    axins.set_ylim(zbounds[1][0], zbounds[1][1])\n",
      "    #axins.set_xticklabels([' '], visible=False)\n",
      "    #axins.set_xticks([0.7e9, 0.72e9, 0.74e9, 0.76e9, 0.78e9])\n",
      "    axins.xaxis.set_major_formatter(pylab.ScalarFormatter(useMathText=True))\n",
      "    axins.set_yticklabels([' '], visible=False)\n",
      "    #axins_twin.set_ylim(6.e7, 1.e8)\n",
      "    axins_twin.set_ylim(zbounds[2][0], zbounds[2][1])\n",
      "    #axins_twin.set_xticklabels([' '], visible=False)\n",
      "    axins_twin.set_yticklabels([' '], visible=False)\n",
      "\n",
      "    #-------------------------------------------------------------------------\n",
      "    # species plot\n",
      "    #-------------------------------------------------------------------------\n",
      "    sp = ax_list[1]    \n",
      "    \n",
      "    # model 1\n",
      "    sp.plot(initialData[:,0], initialData[:,4], color=\"red\", label=r\"$^{4}\\mathrm{He}$\")\n",
      "    sp.plot(initialData[:,0], initialData[:,5], color=\"blue\", label=r\"$^{12}\\mathrm{C}$\")\n",
      "    #    pylab.plot(initialData[:,0], initialData[:,6], color=\"green\", label=r\"$^{16}\\mathrm{O}$\")\n",
      "    \n",
      "    # draw in the sponge star, anelastic cutoff, and base cutoff density\n",
      "    #sp.plot([r_an, r_an ], [0, 1.05], color=\"0.65\")\n",
      "    #sp.plot([r_sp, r_sp ], [0, 1.05], color=\"0.65\")\n",
      "    #sp.plot([r_bc, r_bc ], [0, 1.05], color=\"0.65\")\n",
      "\n",
      "    #pylab.xlabel(\"r (cm)\")\n",
      "    sp.set_ylabel(\"mass fraction\")\n",
      "\n",
      "    #ax = pylab.gca()\n",
      "    sp.xaxis.set_major_formatter(pylab.ScalarFormatter(useMathText=True))\n",
      "    #ax.yaxis.set_major_formatter(pylab.ScalarFormatter(useMathText=True))\n",
      "\n",
      "    # the offset text is the 1.e8 that appears under the axis labels when\n",
      "    # doing scientific notation\n",
      "    sp.tick_params(labeltop='off')\n",
      "    sp.tick_params(labelbottom='off')\n",
      "    sp.xaxis.offsetText.set_visible(False)\n",
      "\n",
      "    sp.set_xlim(rlims[0], rlims[1])\n",
      "    sp.set_ylim(0.0,1.05)\n",
      "\n",
      "    sp.legend(loc=2)\n",
      "\n",
      "    #-------------------------------------------------------------------------\n",
      "    # soundspeed\n",
      "    #-------------------------------------------------------------------------\n",
      "    sp = ax_list[2]    \n",
      "    \n",
      "    sp.set_yscale('log')\n",
      "\n",
      "    # model 1\n",
      "    sp.plot(extraData[:,0], extraData[:,1], color=\"red\")\n",
      "\n",
      "    \n",
      "    # draw in the sponge star, anelastic cutoff, and base cutoff density\n",
      "    #sp.plot([r_an, r_an ], [clims[0], clims[1]], color=\"0.65\")\n",
      "    #sp.plot([r_sp, r_sp ], [clims[0], clims[1]], color=\"0.65\")\n",
      "    #sp.plot([r_bc, r_bc ], [clims[0], clims[1]], color=\"0.65\")\n",
      "    \n",
      "    sp.set_xlabel(\"r (cm)\")\n",
      "    sp.set_ylabel(\"sound speed (cm/s)\")\n",
      "\n",
      "    #ax = pylab.gca()\n",
      "    sp.xaxis.set_major_formatter(pylab.ScalarFormatter(useMathText=True))\n",
      "    #ax.yaxis.set_major_formatter(pylab.ScalarFormatter(useMathText=True))\n",
      "\n",
      "    sp.set_xlim(rlims[0], rlims[1])\n",
      "    sp.set_ylim(clims[0], clims[1])\n",
      "\n",
      "    #-------------------------------------------------------------------------\n",
      "    #pylab.subplots_adjust(hspace=0.1)\n",
      "\n",
      "    #f = pylab.gcf()\n",
      "    fig.set_size_inches(6.0,12.0)\n",
      "    fig.tight_layout()\n",
      "\n",
      "    #fig.savefig(\"initial_model_paper.png\", bbox_inches='tight')\n",
      "    #fig.savefig(\"initial_model_paper.eps\", bbox_inches='tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def check_globals(job_label, stg_dir, work_dir):\n",
      "    \"\"\"Plot globals for run in job_label directory.\"\"\"\n",
      "    #Plot T_peak and M_peak\n",
      "    snapshot(work_dir + '/' + job_label + '/')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def snapshot(curdir):\n",
      "    \"\"\"Display a snapshot of the status of the run in curdir.\"\"\"\n",
      "    \n",
      "    curdir_base = !basename $curdir\n",
      "    found = False\n",
      "    try:\n",
      "        lastout = !ls $curdir | grep .o[0-9] | sort | tail -n 1\n",
      "        full = curdir + lastout[0]\n",
      "        found = True\n",
      "    except IndexError:\n",
      "        print '.o# file not available.'\n",
      "    \n",
      "    if(found):\n",
      "        final_timestep = !grep 'TIME =' $full | tail -n 1\n",
      "        print 'Final timestep for', curdir_base[0], ': ', final_timestep[0]\n",
      "        print ' '\n",
      "        \n",
      "\n",
      "    col_plot(curdir + 'subchandra_temp_diag.out', 1, 2, curdir_base[0] + ' Temp', 'Time [s]', 'Temp [K]')\n",
      "    col_plot(curdir + 'subchandra_vel_diag.out', 1, 4, curdir_base[0] + ' Mach', 'Time [s]', 'Mach #')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot 2D data from a file with data columns using the given columns\n",
      "def col_plot(datafile, xcol, ycol, title, xlab, ylab, xord=0, yord=0):\n",
      "  from matplotlib.ticker import FuncFormatter\n",
      "\n",
      "  #Extract the data\n",
      "  x, y = np.genfromtxt(datafile, comments='#', skip_header=2,usecols=(xcol-1, ycol-1), unpack=True)\n",
      "\n",
      "  #Create plot objects\n",
      "  fig = plt.figure()\n",
      "  axes = fig.add_axes([0.15, 0.1, 0.75, 0.8]) # lower, bottom, width, height (range 0 to 1)\n",
      "  axes.plot(x, y)\n",
      " \n",
      "  #Set plot properties\n",
      "  if(xord > 2):\n",
      "    #If the preferred x order of magnitude > 2, then do some formatting\n",
      "    axes.xaxis.set_major_formatter(FuncFormatter(lambda x, pos: ('%.1f')%(x * pow(10,-xord))))\n",
      "    axes.set_xlabel(xlab + r'$\\times$ $10^{0}$'.format(xord))\n",
      "  else:\n",
      "    axes.set_xlabel(xlab)\n",
      "\n",
      "  if(yord > 2):\n",
      "    #If the preferred y order of magnitude > 2, then do some formatting\n",
      "    axes.yaxis.set_major_formatter(FuncFormatter(lambda x, pos: ('%.1f')%(x * pow(10,-yord))))\n",
      "    axes.set_ylabel(ylab + r'$\\times$ $10^{0}$'.format(yord))\n",
      "  else:\n",
      "    axes.set_ylabel(ylab)\n",
      "\n",
      "  axes.set_title(title)\n",
      "\n",
      "  plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Job creation functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_08130_107_185_3lev(bw=False):\n",
      "    #Model specification and configuration\n",
      "    levels = 3\n",
      "    tcore = 1.0e7\n",
      "    tbase = 1.85e8\n",
      "    Mcore, Mhe = 0.8, 0.13\n",
      "    coarse_res = 256\n",
      "    drdx = 5\n",
      "    r_res = coarse_res * 2**(levels-1) * drdx\n",
      "    octant = \".true.\"\n",
      "        \n",
      "    #Run specification\n",
      "    node_count = 128\n",
      "    mpn = 4  #MPI tasks / node\n",
      "    mpi_tasks = node_count * mpn\n",
      "    omp_thds = 8 #OpenMP threads/MPI task\n",
      "    npn = -1 #NUMA (logical, shared-memory) nodes per node\n",
      "    if(bw):\n",
      "        BW_NUMA = 4\n",
      "        npn = BW_NUMA\n",
      "    else:\n",
      "        TITAN_NUMA = 2  \n",
      "        npn = TITAN_NUMA\n",
      "            \n",
      "    #Build meaningful strings\n",
      "    run_label = '{0:02d}{1:03d}-10{2:1d}-{3:03d}-{4:1d}lev'.format(int(Mcore*10), \n",
      "        int(Mhe*10**3), int(math.log10(tcore)), int(tbase/1.e6), levels)\n",
      "    params_file = '_params.M_WD-{0:03.1f}.M_He-{1:04.3f}'.format(Mcore, Mhe) #This will be created\n",
      "    inputs_file = 'inputs3d.{0:d}.{1:d}dr.eq.dx_{2:d}levs'.format(coarse_res, drdx, levels)\n",
      "    jname = '\"{0:d}^3 base grid, T_core = 10^{1:1d}, T_base = {2:03d} MK -- M_WD={3:g}, M_He={4:g}\"'.format(coarse_res,\n",
      "        int(math.log10(tcore)), int(tbase/1.e6), Mcore, Mhe)\n",
      "    \n",
      "    #The below are set based on the above variables\n",
      "    param_dict = {\n",
      "        \"nx\"       : str(r_res),    \n",
      "        \"M_tot\"    : str(Mcore),\n",
      "        \"M_He\"     : str(Mhe), \n",
      "        \"temp_core\": str(tcore),\n",
      "        \"temp_base\": str(tbase)}\n",
      "    inputs_dict = {\n",
      "        \"job_name\": jname,\n",
      "        \"max_levs\": str(levels),\n",
      "        \"n_cellx\": str(coarse_res),\n",
      "        \"n_celly\": str(coarse_res),\n",
      "        \"n_cellz\": str(coarse_res),\n",
      "        \"max_grid_size_1\": \"32\",\n",
      "        \"max_grid_size_2\": \"64\",\n",
      "        \"max_grid_size_3\": \"128\",\n",
      "        \"the_sfc_threshold\": \"32768\",\n",
      "        \"base_cutoff_density\": \"1.d4\",\n",
      "        \"octant\": octant,\n",
      "        \"bcx_lo\": \"13\", #13 --> Symmetry (see BoxLib/Src/F_BaseLib/bc.f90)\n",
      "        \"bcx_hi\": \"12\", #12 --> Outlet\n",
      "        \"bcy_lo\": \"13\",\n",
      "        \"bcy_hi\": \"12\",\n",
      "        \"bcz_lo\": \"13\",\n",
      "        \"bcz_hi\": \"12\",\n",
      "        \"plot_base_name\": \"\\\"\" + run_label + \"_plt\\\"\",\n",
      "        \"plot_int\": \"-1\",\n",
      "        \"plot_deltat\": \"5.0d0\",\n",
      "        \"check_base_name\": \"\\\"\" + run_label + \"_chk\\\"\",\n",
      "        \"chk_int\": \"10\",}\n",
      "    job_dict = {\n",
      "        \"#PBS -N\": \" \" + run_label,\n",
      "        \"#PBS -q\": \" normal\",\n",
      "        \"export OMP_NUM_THREADS\": \"=\" + str(omp_thds)}\n",
      "    if(bw):\n",
      "        job_dict[\"#PBS -l\"] = \" walltime=04:00:00,nodes=\" + str(node_count) + \":ppn=32:xe\"\n",
      "        job_dict[\"# this\"] = \" script runs with \" + str(omp_thds) + \" threads, \" + str(mpn) +\" MPI tasks/node, and \" + str(node_count) + \" nodes on Blue Waters\"\n",
      "    else:\n",
      "        job_dict[\"#PBS -l\"] = \" walltime=04:00:00,nodes=\" + str(node_count)\n",
      "        job_dict[\"# this\"] = \" script runs with \" + str(omp_thds) + \" threads, \" + str(mpn) +\" MPI tasks/node, and \" + str(node_count) + \" nodes on Titan\"\n",
      "    if(mpn < npn):\n",
      "        job_dict[\"aprun\"] = \" -n \" + str(mpi_tasks) + \" -N \" + str(mpn) + \" -d $OMP_NUM_THREADS -ss ./main.Linux.Cray.mpi.omp.exe \" + inputs_file + \" ${restartString}\"\n",
      "    else:\n",
      "        job_dict[\"aprun\"] = \" -n \" + str(mpi_tasks) + \" -S \" + str(mpn/npn) + \" -d $OMP_NUM_THREADS -ss ./main.Linux.Cray.mpi.omp.exe \" + inputs_file + \" ${restartString}\"\n",
      "    create_run(run_label, \n",
      "               STG_DIR + \"/\" + run_label + \"/run/\" + params_file, \n",
      "               param_dict,\n",
      "               STG_DIR + \"/\" + run_label + \"/run/\" + inputs_file,\n",
      "               inputs_dict,\n",
      "               job_dict, bw=bw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_08130_107_185_3lev_full(bw=True):\n",
      "    #Model specification and configuration\n",
      "    levels = 3\n",
      "    tcore = 1.0e7\n",
      "    tbase = 1.85e8\n",
      "    Mcore, Mhe = 0.8, 0.13\n",
      "    coarse_res = 256\n",
      "    drdx = 5\n",
      "    r_res = coarse_res * 2**(levels-1) * drdx\n",
      "    octant = \".false.\"\n",
      "        \n",
      "    #Run specification\n",
      "    node_count = 128\n",
      "    mpn = 4  #MPI tasks / node\n",
      "    mpi_tasks = node_count * mpn\n",
      "    omp_thds = 8 #OpenMP threads/MPI task\n",
      "    npn = -1 #NUMA (logical, shared-memory) nodes per node\n",
      "    if(bw):\n",
      "        BW_NUMA = 4\n",
      "        npn = BW_NUMA\n",
      "    else:\n",
      "        TITAN_NUMA = 2  \n",
      "        npn = TITAN_NUMA\n",
      "            \n",
      "    #Build meaningful strings\n",
      "    run_label = '{0:02d}{1:03d}-10{2:1d}-{3:03d}-{4:1d}lev-full'.format(int(Mcore*10), \n",
      "        int(Mhe*10**3), int(math.log10(tcore)), int(tbase/1.e6), levels)\n",
      "    params_file = '_params.M_WD-{0:03.1f}.M_He-{1:04.3f}'.format(Mcore, Mhe) #This will be created\n",
      "    inputs_file = 'inputs3d.{0:d}.{1:d}dr.eq.dx_{2:d}levs'.format(coarse_res, drdx, levels)\n",
      "    jname = '\"{0:d}^3 base grid, T_core = 10^{1:1d}, T_base = {2:03d} MK -- M_WD={3:g}, M_He={4:g}\"'.format(coarse_res,\n",
      "        int(math.log10(tcore)), int(tbase/1.e6), Mcore, Mhe)\n",
      "    \n",
      "    #The below are set based on the above variables\n",
      "    param_dict = {\n",
      "        \"nx\"       : str(r_res),    \n",
      "        \"M_tot\"    : str(Mcore),\n",
      "        \"M_He\"     : str(Mhe), \n",
      "        \"temp_core\": str(tcore),\n",
      "        \"temp_base\": str(tbase)}\n",
      "    inputs_dict = {\n",
      "        \"job_name\": jname,\n",
      "        \"max_levs\": str(levels),\n",
      "        \"n_cellx\": str(coarse_res),\n",
      "        \"n_celly\": str(coarse_res),\n",
      "        \"n_cellz\": str(coarse_res),\n",
      "        \"max_grid_size_1\": \"32\",\n",
      "        \"max_grid_size_2\": \"64\",\n",
      "        \"max_grid_size_3\": \"128\",\n",
      "        \"the_sfc_threshold\": \"32768\",\n",
      "        \"base_cutoff_density\": \"1.d4\",\n",
      "        \"octant\": octant,\n",
      "        \"bcx_lo\": \"12\", #13 --> Symmetry (see BoxLib/Src/F_BaseLib/bc.f90)\n",
      "        \"bcx_hi\": \"12\", #12 --> Outlet\n",
      "        \"bcy_lo\": \"12\",\n",
      "        \"bcy_hi\": \"12\",\n",
      "        \"bcz_lo\": \"12\",\n",
      "        \"bcz_hi\": \"12\",\n",
      "        \"plot_base_name\": \"\\\"\" + run_label + \"_plt\\\"\",\n",
      "        \"plot_int\": \"-1\",\n",
      "        \"plot_deltat\": \"5.0d0\",\n",
      "        \"check_base_name\": \"\\\"\" + run_label + \"_chk\\\"\",\n",
      "        \"chk_int\": \"5\",}\n",
      "    job_dict = {\n",
      "        \"#PBS -N\": \" \" + run_label,\n",
      "        \"#PBS -q\": \" normal\",\n",
      "        \"export OMP_NUM_THREADS\": \"=\" + str(omp_thds)}\n",
      "    if(bw):\n",
      "        job_dict[\"#PBS -l\"] = \" walltime=04:00:00,nodes=\" + str(node_count) + \":ppn=32:xe\"\n",
      "        job_dict[\"# this\"] = \" script runs with \" + str(omp_thds) + \" threads, \" + str(mpn) +\" MPI tasks/node, and \" + str(node_count) + \" nodes on Blue Waters\"\n",
      "    else:\n",
      "        job_dict[\"#PBS -l\"] = \" walltime=04:00:00,nodes=\" + str(node_count)\n",
      "        job_dict[\"# this\"] = \" script runs with \" + str(omp_thds) + \" threads, \" + str(mpn) +\" MPI tasks/node, and \" + str(node_count) + \" nodes on Titan\"\n",
      "    if(mpn < npn):\n",
      "        job_dict[\"aprun\"] = \" -n \" + str(mpi_tasks) + \" -N \" + str(mpn) + \" -d $OMP_NUM_THREADS -ss ./main.Linux.Cray.mpi.omp.exe \" + inputs_file + \" ${restartString}\"\n",
      "    else:\n",
      "        job_dict[\"aprun\"] = \" -n \" + str(mpi_tasks) + \" -S \" + str(mpn/npn) + \" -d $OMP_NUM_THREADS -ss ./main.Linux.Cray.mpi.omp.exe \" + inputs_file + \" ${restartString}\"\n",
      "    create_run(run_label, \n",
      "               STG_DIR + \"/\" + run_label + \"/run/\" + params_file, \n",
      "               param_dict,\n",
      "               STG_DIR + \"/\" + run_label + \"/run/\" + inputs_file,\n",
      "               inputs_dict,\n",
      "               job_dict, bw=bw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_08130_107_185_4lev_full(bw=True):\n",
      "    #Model specification and configuration\n",
      "    levels = 4\n",
      "    tcore = 1.0e7\n",
      "    tbase = 1.85e8\n",
      "    Mcore, Mhe = 0.8, 0.13\n",
      "    coarse_res = 256\n",
      "    drdx = 5\n",
      "    r_res = coarse_res * 2**(levels-1) * drdx\n",
      "    octant = \".false.\"\n",
      "        \n",
      "    #Run specification\n",
      "    node_count = 128\n",
      "    mpn = 4  #MPI tasks / node\n",
      "    mpi_tasks = node_count * mpn\n",
      "    omp_thds = 8 #OpenMP threads/MPI task\n",
      "    npn = -1 #NUMA (logical, shared-memory) nodes per node\n",
      "    if(bw):\n",
      "        BW_NUMA = 4\n",
      "        npn = BW_NUMA\n",
      "    else:\n",
      "        TITAN_NUMA = 2  \n",
      "        npn = TITAN_NUMA\n",
      "            \n",
      "    #Build meaningful strings\n",
      "    run_label = '{0:02d}{1:03d}-10{2:1d}-{3:03d}-{4:1d}lev-full'.format(int(Mcore*10), \n",
      "        int(Mhe*10**3), int(math.log10(tcore)), int(tbase/1.e6), levels)\n",
      "    params_file = '_params.M_WD-{0:03.1f}.M_He-{1:04.3f}'.format(Mcore, Mhe) #This will be created\n",
      "    inputs_file = 'inputs3d.{0:d}.{1:d}dr.eq.dx_{2:d}levs'.format(coarse_res, drdx, levels)\n",
      "    jname = '\"{0:d}^3 base grid, T_core = 10^{1:1d}, T_base = {2:03d} MK -- M_WD={3:g}, M_He={4:g}\"'.format(coarse_res,\n",
      "        int(math.log10(tcore)), int(tbase/1.e6), Mcore, Mhe)\n",
      "    \n",
      "    #The below are set based on the above variables\n",
      "    param_dict = {\n",
      "        \"nx\"       : str(r_res),    \n",
      "        \"M_tot\"    : str(Mcore),\n",
      "        \"M_He\"     : str(Mhe), \n",
      "        \"temp_core\": str(tcore),\n",
      "        \"temp_base\": str(tbase)}\n",
      "    inputs_dict = {\n",
      "        \"job_name\": jname,\n",
      "        \"max_levs\": str(levels),\n",
      "        \"n_cellx\": str(coarse_res),\n",
      "        \"n_celly\": str(coarse_res),\n",
      "        \"n_cellz\": str(coarse_res),\n",
      "        \"max_grid_size_1\": \"32\",\n",
      "        \"max_grid_size_2\": \"64\",\n",
      "        \"max_grid_size_3\": \"128\",\n",
      "        \"the_sfc_threshold\": \"32768\",\n",
      "        \"base_cutoff_density\": \"1.d4\",\n",
      "        \"octant\": octant,\n",
      "        \"bcx_lo\": \"12\", #13 --> Symmetry (see BoxLib/Src/F_BaseLib/bc.f90)\n",
      "        \"bcx_hi\": \"12\", #12 --> Outlet\n",
      "        \"bcy_lo\": \"12\",\n",
      "        \"bcy_hi\": \"12\",\n",
      "        \"bcz_lo\": \"12\",\n",
      "        \"bcz_hi\": \"12\",\n",
      "        \"plot_base_name\": \"\\\"\" + run_label + \"_plt\\\"\",\n",
      "        \"plot_int\": \"-1\",\n",
      "        \"plot_deltat\": \"5.0d0\",\n",
      "        \"check_base_name\": \"\\\"\" + run_label + \"_chk\\\"\",\n",
      "        \"chk_int\": \"5\",}\n",
      "    job_dict = {\n",
      "        \"#PBS -N\": \" \" + run_label,\n",
      "        \"#PBS -q\": \" normal\",\n",
      "        \"export OMP_NUM_THREADS\": \"=\" + str(omp_thds)}\n",
      "    if(bw):\n",
      "        job_dict[\"#PBS -l\"] = \" walltime=04:00:00,nodes=\" + str(node_count) + \":ppn=32:xe\"\n",
      "        job_dict[\"# this\"] = \" script runs with \" + str(omp_thds) + \" threads, \" + str(mpn) +\" MPI tasks/node, and \" + str(node_count) + \" nodes on Blue Waters\"\n",
      "    else:\n",
      "        job_dict[\"#PBS -l\"] = \" walltime=04:00:00,nodes=\" + str(node_count)\n",
      "        job_dict[\"# this\"] = \" script runs with \" + str(omp_thds) + \" threads, \" + str(mpn) +\" MPI tasks/node, and \" + str(node_count) + \" nodes on Titan\"\n",
      "    if(mpn < npn):\n",
      "        job_dict[\"aprun\"] = \" -n \" + str(mpi_tasks) + \" -N \" + str(mpn) + \" -d $OMP_NUM_THREADS -ss ./main.Linux.Cray.mpi.omp.exe \" + inputs_file + \" ${restartString}\"\n",
      "    else:\n",
      "        job_dict[\"aprun\"] = \" -n \" + str(mpi_tasks) + \" -S \" + str(mpn/npn) + \" -d $OMP_NUM_THREADS -ss ./main.Linux.Cray.mpi.omp.exe \" + inputs_file + \" ${restartString}\"\n",
      "    create_run(run_label, \n",
      "               STG_DIR + \"/\" + run_label + \"/run/\" + params_file, \n",
      "               param_dict,\n",
      "               STG_DIR + \"/\" + run_label + \"/run/\" + inputs_file,\n",
      "               inputs_dict,\n",
      "               job_dict, bw=bw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}