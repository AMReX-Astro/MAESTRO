#!/bin/ksh -p

#----------------------------------------------------------------------------
# user modifiable variables:

# pidfile is a lock file that is used to make sure that only one instance 
# of this script is working on the current directory
pidfile=process.pid


# set the prefix of the plotfiles and checkpoint files
plt_prefix=plt
chk_prefix=chk??[05]??


# set the full name of the analysis routines -- note, these need to be in 
# the working directory so compute nodes can access them.
fwdconvect=./fwdconvect.Linux.PathScale.exe
fsnapshot3d=./fsnapshot3d.Linux.PathScale.exe

# set the name of the variable we want to process with fsnapshot
pvar=radial_velocity


# directory to archive to on HPSS -- set this to the working directory
work_dir=`pwd`
HPSS_DIR=`basename $work_dir`


#----------------------------------------------------------------------------
# initialization stuff

# check to make sure that the lock file does not already exist.
if [ -f $pidfile ]; then
  echo 2>&1 "process lock file " $pidfile " already exists"
  exit -1
fi

# create the lock file
echo $$ > $pidfile

# if our process if killed, remove the lock file first
trap '/bin/rm -f $pidfile' EXIT HUP TERM XCPU KILL

# Number of seconds to sleep before checking again.
N=60



#----------------------------------------------------------------------------
# make storage directories

# once we process a file, we will move the plotfiles into the plotfiles/
# directory.  This then hides them from the script, so if the system
# later purges the files in the pltXXXXX directory and the .processed
# file, we don't overwrite our archived data with a tarred empty
# directory structure

if [ ! -d plotfiles ]; then
  mkdir plotfiles
fi


# also create directories to hold the images and .averages file 
# produced -- this just keeps the run directory clean

if [ ! -d images ]; then
  mkdir images
fi

if [ ! -d averages ]; then
  mkdir averages
fi


#----------------------------------------------------------------------------
# the processing function

# Process Files.  Once a plotfile is successfully processed, we will output
# a file pltXXXXX.processed (checkpoint files are only archived, with a
# chkXXXXX.processed file appearing once the archiving is successful).  
# Subsequent invocations of this routine will skip over any plotfiles or
# checkpoint files that have a corresponding .processed file.


function process_files
{
  if [ ! -f $pidfile ]; then
    echo "process: $pidfile has been removed, exiting"
    exit
  fi


  # plotfiles

  # Take all but the final plt file -- we want to ensure they're completely 
  # written to disk.  Strip out any tar files that are lying around as well 
  # as pltXXXXX.processed files.
  #pltlist=$(ls -d ${plt_prefix}* 2>/dev/null | grep -v tar | grep -v processed)
  pltlist=$(find . -maxdepth 1 -type d -name "${plt_prefix}*" -print | sort)

  if [ "$pltlist" ]; then
    nl=$(echo "$pltlist" | wc -l)
    nl=$(expr $nl - 1)
    if [ $nl -eq 0 ]; then
      pltlist=""
    else
      pltlist=$(echo "$pltlist" | head -$nl)
    fi
  fi


  for dir in ${pltlist}
  do
    if [ -d ${dir} ]; then

      if [ ! -f ${dir}.processed ]; then

        # do processing

        echo "running fwdconvect on ${dir}"
        ${fwdconvect} -p ${dir} -s ${dir}.averages

        echo "running fsnapshot3d on ${dir}"
        ${fsnapshot3d} -p ${dir} -n 1 -cname "${pvar}" -m -1.e6 -M 1.e6
        ${fsnapshot3d} -p ${dir} -n 2 -cname "${pvar}" -m -1.e6 -M 1.e6
        ${fsnapshot3d} -p ${dir} -n 3 -cname "${pvar}" -m -1.e6 -M 1.e6

        # store the file on HPSS
        htar -cvf ${HPSS_DIR}/${dir}.tar ${dir} 

	# htar's exit status is 0 if it was successful.  The variable $? 
	# holds the exit status of the previous command

	if [ $? -eq 0 ]; then

          # mark this file as processed so we skip it next time
          date > ${dir}.processed

	  # move the plotfile into the plotfiles directory
	  mv ${dir} plotfiles/

	  # the find command will find the plotfiles even in their 
	  # subdirectory, so we need to move the corresponding .processed 
	  # file there too.
	  mv ${dir}.processed plotfiles/

	  mv ${dir}.averages averages/

	  mv ${dir}*.ppm images/
        fi

      fi   # end test of whether plotfile already processed

    fi   # end test of whether plotfile is a directory (as it should be)

  done


  # checkpoint files

  # Take all but the final chk file -- we want to ensure they're completely 
  # written to disk.  Strip out any tar files that are lying around as well 
  # as chkXXXXX.processed files.
  #chklist=$(ls -d ${chk_prefix}* 2>/dev/null | grep -v tar | grep -v processed)
  chklist=$(find . -type d -name "${chk_prefix}*" -print | sort)

  if [ "$chklist" ]; then
    nl=$(echo "$chklist" | wc -l)
    nl=$(expr $nl - 1)
    if [ $nl -eq 0 ]; then
      chklist=""
    else
      chklist=$(echo "$chklist" | head -$nl)
    fi
  fi


  for dir in ${chklist}
  do
    if [ -d ${dir} ]; then

      if [ ! -f ${dir}.processed ]; then

        # store the file on HPSS
        htar -cvf ${HPSS_DIR}/${dir}.tar ${dir} 

	# htar's exit status is 0 if it was successful.  The variable $? 
	# holds the exit status of the previous command

	if [ $? -eq 0 ]; then

          # mark this file as processed so we skip it next time
          date > ${dir}.processed
        fi

      fi

    fi
  done

}


#----------------------------------------------------------------------------
# the main loop

# Looping waiting for plt and chk directories to appear.

while true
do
  process_files
  sleep $N
done
